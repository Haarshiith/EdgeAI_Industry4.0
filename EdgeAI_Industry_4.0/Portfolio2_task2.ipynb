{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea84eff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_CLASSES = 4  # Person, Helmet, Safety-vest, No-PPE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "IMG_SIZE = 224\n",
    "\n",
    "class PPEDataset(Dataset):\n",
    "    \"\"\"Dataset for PPE detection - handles multiple objects per image\"\"\"\n",
    "    def __init__(self, images_dir, labels_dir, transform=None, mode='crop_objects'):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.labels_dir = Path(labels_dir)\n",
    "        self.transform = transform\n",
    "        self.mode = mode  # 'multi_label' or 'dominant_class' or 'crop_objects'\n",
    "        \n",
    "        # Get all image files\n",
    "        self.image_files = sorted(list(self.images_dir.glob('*.jpg')) + \n",
    "                                  list(self.images_dir.glob('*.png')) +\n",
    "                                  list(self.images_dir.glob('*.jpeg')))\n",
    "        \n",
    "        print(f\"Found {len(self.image_files)} images in {images_dir}\")\n",
    "        \n",
    "        if self.mode == 'crop_objects':\n",
    "            # Create separate samples for each object\n",
    "            self.samples = []\n",
    "            self._create_object_crops()\n",
    "        \n",
    "    def _create_object_crops(self):\n",
    "        \"\"\"Create individual samples for each object in images\"\"\"\n",
    "        for img_path in self.image_files:\n",
    "            label_path = self.labels_dir / (img_path.stem + '.txt')\n",
    "            if label_path.exists():\n",
    "                with open(label_path, 'r') as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) >= 5:\n",
    "                            class_id = int(parts[0])\n",
    "                            x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                            self.samples.append({\n",
    "                                'image_path': img_path,\n",
    "                                'class_id': class_id,\n",
    "                                'bbox': (x_center, y_center, width, height)\n",
    "                            })\n",
    "        print(f\"Created {len(self.samples)} object samples from images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.mode == 'crop_objects':\n",
    "            return len(self.samples)\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'crop_objects':\n",
    "            return self._get_cropped_object(idx)\n",
    "        elif self.mode == 'dominant_class':\n",
    "            return self._get_dominant_class(idx)\n",
    "        else:  # multi_label\n",
    "            return self._get_multi_label(idx)\n",
    "    \n",
    "    def _get_cropped_object(self, idx):\n",
    "        \"\"\"Get a cropped object from the image\"\"\"\n",
    "        sample = self.samples[idx]\n",
    "        image = cv2.imread(str(sample['image_path']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        # Convert YOLO format to pixel coordinates\n",
    "        x_center, y_center, width, height = sample['bbox']\n",
    "        x1 = int((x_center - width/2) * w)\n",
    "        y1 = int((y_center - height/2) * h)\n",
    "        x2 = int((x_center + width/2) * w)\n",
    "        y2 = int((y_center + height/2) * h)\n",
    "        \n",
    "        # Ensure coordinates are within bounds\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w, x2), min(h, y2)\n",
    "        \n",
    "        # Crop the object\n",
    "        cropped = image[y1:y2, x1:x2]\n",
    "        \n",
    "        # Handle empty crops\n",
    "        if cropped.size == 0:\n",
    "            cropped = image\n",
    "        \n",
    "        if self.transform:\n",
    "            cropped = self.transform(cropped)\n",
    "        \n",
    "        return cropped, sample['class_id']\n",
    "    \n",
    "    def _get_dominant_class(self, idx):\n",
    "        \"\"\"Get the most common class in the image\"\"\"\n",
    "        img_path = self.image_files[idx]\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Read all labels and find dominant class\n",
    "        label_path = self.labels_dir / (img_path.stem + '.txt')\n",
    "        classes = []\n",
    "        if label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        classes.append(int(parts[0]))\n",
    "        \n",
    "        # Get most common class, default to 0\n",
    "        if classes:\n",
    "            label = Counter(classes).most_common(1)[0][0]\n",
    "        else:\n",
    "            label = 0\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def _get_multi_label(self, idx):\n",
    "        \"\"\"Get multi-label vector for the image\"\"\"\n",
    "        img_path = self.image_files[idx]\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Create multi-label vector\n",
    "        label_vector = torch.zeros(NUM_CLASSES)\n",
    "        label_path = self.labels_dir / (img_path.stem + '.txt')\n",
    "        \n",
    "        if label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        class_id = int(parts[0])\n",
    "                        if 0 <= class_id < NUM_CLASSES:\n",
    "                            label_vector[class_id] = 1\n",
    "        \n",
    "        # If no labels, set first class as default\n",
    "        if label_vector.sum() == 0:\n",
    "            label_vector[0] = 1\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label_vector\n",
    "\n",
    "def create_model(multi_label=False):\n",
    "    \"\"\"Create MobileNetV2 model for PPE classification\"\"\"\n",
    "    model = models.mobilenet_v2(pretrained=True)\n",
    "    \n",
    "    if multi_label:\n",
    "        # For multi-label classification, use sigmoid activation\n",
    "        model.classifier[1] = nn.Linear(model.last_channel, NUM_CLASSES)\n",
    "    else:\n",
    "        # For single-label classification\n",
    "        model.classifier[1] = nn.Linear(model.last_channel, NUM_CLASSES)\n",
    "    \n",
    "    return model.to(DEVICE)\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, multi_label=False):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        \n",
    "        if multi_label:\n",
    "            labels = labels.to(DEVICE)\n",
    "        else:\n",
    "            labels = labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if not multi_label:\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        else:\n",
    "            # For multi-label, calculate accuracy differently\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total += labels.numel()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "def evaluate(model, dataloader, multi_label=False):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    inference_times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(DEVICE)\n",
    "            \n",
    "            if multi_label:\n",
    "                labels = labels.to(DEVICE)\n",
    "            else:\n",
    "                labels = labels.to(DEVICE)\n",
    "            \n",
    "            start = time.time()\n",
    "            outputs = model(images)\n",
    "            inference_times.append(time.time() - start)\n",
    "            \n",
    "            if not multi_label:\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "            else:\n",
    "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                total += labels.numel()\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    avg_time = np.mean(inference_times) * 1000  # Convert to ms\n",
    "    return accuracy, avg_time\n",
    "\n",
    "def get_model_size(model):\n",
    "    \"\"\"Get actual model size in MB (counting only non-zero parameters)\"\"\"\n",
    "    param_size = 0\n",
    "    threshold = 1e-8\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        # Count non-zero parameters\n",
    "        non_zero = torch.sum(torch.abs(param) > threshold).item()\n",
    "        param_size += non_zero * param.element_size()\n",
    "    \n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_mb = (param_size + buffer_size) / 1024**2\n",
    "    return size_mb\n",
    "\n",
    "def get_sparsity(model):\n",
    "    \"\"\"Calculate model sparsity (% of near-zero weights)\"\"\"\n",
    "    zero_params = 0\n",
    "    total_params = 0\n",
    "    threshold = 1e-8  # Consider values below this as pruned\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        zero_params += torch.sum(torch.abs(param) < threshold).item()\n",
    "        total_params += param.nelement()\n",
    "    \n",
    "    return 100. * zero_params / total_params\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count total and non-zero parameters\"\"\"\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    threshold = 1e-8\n",
    "    non_zero = sum(torch.sum(torch.abs(p) > threshold).item() for p in model.parameters())\n",
    "    return total, non_zero\n",
    "\n",
    "# ==============================================================================\n",
    "# PRUNING HEURISTIC 1: Magnitude-based Pruning (L1)\n",
    "# ==============================================================================\n",
    "def magnitude_pruning(model, amount):\n",
    "    \"\"\"\n",
    "    Prune weights with smallest L1 magnitude globally across all layers.\n",
    "    This is the most common and effective pruning heuristic.\n",
    "    \"\"\"\n",
    "    parameters_to_prune = []\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            parameters_to_prune.append((module, 'weight'))\n",
    "    \n",
    "    # Global unstructured pruning based on L1 magnitude\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=amount,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "# PRUNING HEURISTIC 2: Random Pruning\n",
    "# ==============================================================================\n",
    "def random_pruning(model, amount):\n",
    "    \"\"\"\n",
    "    Randomly prune weights - useful as a baseline to compare against \n",
    "    structured pruning methods. Shows importance of selecting which weights to prune.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            prune.random_unstructured(module, name='weight', amount=amount)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "# PRUNING HEURISTIC 3: Layer-wise Proportional Pruning\n",
    "# ==============================================================================\n",
    "def layerwise_pruning(model, amount):\n",
    "    \"\"\"\n",
    "    Prune each layer independently with the same proportion.\n",
    "    This maintains the relative capacity of each layer, which can be beneficial\n",
    "    for preserving model structure.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # Prune each layer independently\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "# Making Pruning Permanent\n",
    "# ==============================================================================\n",
    "def make_pruning_permanent(model):\n",
    "    \"\"\"\n",
    "    Remove pruning reparameterization to get actual model size reduction.\n",
    "    This converts masked weights to actual zeros and removes the mask buffers.\n",
    "    \"\"\"\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            try:\n",
    "                prune.remove(module, 'weight')\n",
    "            except:\n",
    "                pass\n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "# Fine-tuning Functions\n",
    "# ==============================================================================\n",
    "def fine_tune(model, train_loader, val_loader, epochs=3, multi_label=False, lr=0.001):\n",
    "    \"\"\"Fine-tune pruned model\"\"\"\n",
    "    if multi_label:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, multi_label)\n",
    "        val_acc, _ = evaluate(model, val_loader, multi_label)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "        \n",
    "        print(f\"  Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "# Iterative Pruning Strategy\n",
    "# ==============================================================================\n",
    "def iterative_pruning(model, train_loader, val_loader, target_sparsity, steps=5, \n",
    "                     multi_label=False, pruning_fn=magnitude_pruning):\n",
    "    \"\"\"\n",
    "    Iteratively prune and fine-tune in multiple steps.\n",
    "    Gradually increases sparsity, allowing the model to adapt at each step.\n",
    "    Generally produces better results than one-shot pruning.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Calculate pruning amount per step\n",
    "    # We need to account for cumulative pruning\n",
    "    remaining = 1.0\n",
    "    prune_amounts = []\n",
    "    for step in range(steps):\n",
    "        target_remaining = 1.0 - ((step + 1) / steps * target_sparsity)\n",
    "        step_amount = 1.0 - (target_remaining / remaining)\n",
    "        prune_amounts.append(step_amount)\n",
    "        remaining = target_remaining\n",
    "    \n",
    "    for step in range(steps):\n",
    "        print(f\"\\nIterative Pruning - Step {step+1}/{steps}\")\n",
    "        print(f\"Pruning {prune_amounts[step]*100:.1f}% of remaining weights...\")\n",
    "        \n",
    "        # Prune\n",
    "        model = pruning_fn(model, prune_amounts[step])\n",
    "        \n",
    "        # Fine-tune with fewer epochs per step\n",
    "        model = fine_tune(model, train_loader, val_loader, epochs=2, multi_label=multi_label, lr=0.0005)\n",
    "        \n",
    "        # Make pruning permanent before evaluation\n",
    "        model = make_pruning_permanent(model)\n",
    "        \n",
    "        # Evaluate\n",
    "        sparsity = get_sparsity(model)\n",
    "        accuracy, inf_time = evaluate(model, val_loader, multi_label)\n",
    "        size_mb = get_model_size(model)\n",
    "        total_params, non_zero_params = count_parameters(model)\n",
    "        \n",
    "        results.append({\n",
    "            'step': step + 1,\n",
    "            'sparsity': sparsity,\n",
    "            'accuracy': accuracy,\n",
    "            'size_mb': size_mb,\n",
    "            'inf_time': inf_time,\n",
    "            'total_params': total_params,\n",
    "            'non_zero_params': non_zero_params\n",
    "        })\n",
    "        \n",
    "        print(f\"Step {step+1} Results:\")\n",
    "        print(f\"  Sparsity: {sparsity:.2f}%\")\n",
    "        print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"  Size: {size_mb:.2f} MB\")\n",
    "        print(f\"  Parameters: {non_zero_params:,} / {total_params:,}\")\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "# ==============================================================================\n",
    "# One-shot Pruning Strategy\n",
    "# ==============================================================================\n",
    "def oneshot_pruning(model, train_loader, val_loader, target_sparsity, \n",
    "                   multi_label=False, pruning_fn=magnitude_pruning):\n",
    "    \"\"\"\n",
    "    Prune all at once to target sparsity, then fine-tune.\n",
    "    Faster but may result in lower accuracy compared to iterative pruning.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    print(f\"\\nOne-shot Pruning - Target Sparsity: {target_sparsity*100:.1f}%\")\n",
    "    \n",
    "    # Prune\n",
    "    model = pruning_fn(model, target_sparsity)\n",
    "    \n",
    "    # Fine-tune with more epochs to recover\n",
    "    model = fine_tune(model, train_loader, val_loader, epochs=5, multi_label=multi_label, lr=0.0005)\n",
    "    \n",
    "    # Make pruning permanent\n",
    "    model = make_pruning_permanent(model)\n",
    "    \n",
    "    # Evaluate\n",
    "    sparsity = get_sparsity(model)\n",
    "    accuracy, inf_time = evaluate(model, val_loader, multi_label)\n",
    "    size_mb = get_model_size(model)\n",
    "    total_params, non_zero_params = count_parameters(model)\n",
    "    \n",
    "    results.append({\n",
    "        'sparsity': sparsity,\n",
    "        'accuracy': accuracy,\n",
    "        'size_mb': size_mb,\n",
    "        'inf_time': inf_time,\n",
    "        'total_params': total_params,\n",
    "        'non_zero_params': non_zero_params\n",
    "    })\n",
    "    \n",
    "    print(f\"Results:\")\n",
    "    print(f\"  Sparsity: {sparsity:.2f}%\")\n",
    "    print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"  Size: {size_mb:.2f} MB\")\n",
    "    print(f\"  Parameters: {non_zero_params:,} / {total_params:,}\")\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "# ==============================================================================\n",
    "# Visualization Functions\n",
    "# ==============================================================================\n",
    "def plot_comprehensive_results(baseline, mag_results, rand_results, layer_results, \n",
    "                              iter_results, oneshot_results):\n",
    "    \"\"\"Create comprehensive visualization of all pruning experiments\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # ========== Plot 1: Accuracy vs Sparsity (All Methods) ==========\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    ax1.axhline(y=baseline['accuracy'], color='green', linestyle='--', \n",
    "                label='Baseline', linewidth=2.5, alpha=0.7)\n",
    "    \n",
    "    if mag_results:\n",
    "        sparsities = [r['sparsity'] for r in mag_results]\n",
    "        accuracies = [r['accuracy'] for r in mag_results]\n",
    "        ax1.plot(sparsities, accuracies, 'o-', label='Magnitude Pruning', \n",
    "                linewidth=2.5, markersize=8, color='#2E86AB')\n",
    "    \n",
    "    if rand_results:\n",
    "        sparsities = [r['sparsity'] for r in rand_results]\n",
    "        accuracies = [r['accuracy'] for r in rand_results]\n",
    "        ax1.plot(sparsities, accuracies, 's-', label='Random Pruning', \n",
    "                linewidth=2.5, markersize=8, color='#A23B72')\n",
    "    \n",
    "    if layer_results:\n",
    "        sparsities = [r['sparsity'] for r in layer_results]\n",
    "        accuracies = [r['accuracy'] for r in layer_results]\n",
    "        ax1.plot(sparsities, accuracies, '^-', label='Layer-wise Pruning', \n",
    "                linewidth=2.5, markersize=8, color='#F18F01')\n",
    "    \n",
    "    if iter_results:\n",
    "        sparsities = [r['sparsity'] for r in iter_results]\n",
    "        accuracies = [r['accuracy'] for r in iter_results]\n",
    "        ax1.plot(sparsities, accuracies, 'D-', label='Iterative (Magnitude)', \n",
    "                linewidth=2.5, markersize=8, color='#C73E1D')\n",
    "    \n",
    "    if oneshot_results:\n",
    "        sparsities = [r['sparsity'] for r in oneshot_results]\n",
    "        accuracies = [r['accuracy'] for r in oneshot_results]\n",
    "        ax1.plot(sparsities, accuracies, 'P-', label='One-shot (Magnitude)', \n",
    "                linewidth=2.5, markersize=12, color='#6A4C93')\n",
    "    \n",
    "    ax1.set_xlabel('Sparsity (%)', fontsize=13, fontweight='bold')\n",
    "    ax1.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold')\n",
    "    ax1.set_title('Accuracy vs Sparsity - All Pruning Methods', fontsize=15, fontweight='bold')\n",
    "    ax1.legend(fontsize=10, loc='best')\n",
    "    ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax1.set_xlim(left=-5)\n",
    "    \n",
    "    # ========== Plot 2: Model Size vs Sparsity ==========\n",
    "    ax2 = fig.add_subplot(gs[0, 2])\n",
    "    ax2.axhline(y=baseline['size_mb'], color='green', linestyle='--', \n",
    "                label='Baseline', linewidth=2.5, alpha=0.7)\n",
    "    \n",
    "    if mag_results:\n",
    "        sparsities = [r['sparsity'] for r in mag_results]\n",
    "        sizes = [r['size_mb'] for r in mag_results]\n",
    "        ax2.plot(sparsities, sizes, 'o-', label='Magnitude', \n",
    "                linewidth=2, markersize=7, color='#2E86AB')\n",
    "    \n",
    "    if iter_results:\n",
    "        sparsities = [r['sparsity'] for r in iter_results]\n",
    "        sizes = [r['size_mb'] for r in iter_results]\n",
    "        ax2.plot(sparsities, sizes, 'D-', label='Iterative', \n",
    "                linewidth=2, markersize=7, color='#C73E1D')\n",
    "    \n",
    "    ax2.set_xlabel('Sparsity (%)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Model Size (MB)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Model Size Reduction', fontsize=13, fontweight='bold')\n",
    "    ax2.legend(fontsize=9)\n",
    "    ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # ========== Plot 3: Inference Time vs Sparsity ==========\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax3.axhline(y=baseline['inf_time'], color='green', linestyle='--', \n",
    "                label='Baseline', linewidth=2.5, alpha=0.7)\n",
    "    \n",
    "    if mag_results:\n",
    "        sparsities = [r['sparsity'] for r in mag_results]\n",
    "        times = [r['inf_time'] for r in mag_results]\n",
    "        ax3.plot(sparsities, times, 'o-', label='Magnitude', \n",
    "                linewidth=2, markersize=7, color='#2E86AB')\n",
    "    \n",
    "    if iter_results:\n",
    "        sparsities = [r['sparsity'] for r in iter_results]\n",
    "        times = [r['inf_time'] for r in iter_results]\n",
    "        ax3.plot(sparsities, times, 'D-', label='Iterative', \n",
    "                linewidth=2, markersize=7, color='#C73E1D')\n",
    "    \n",
    "    ax3.set_xlabel('Sparsity (%)', fontsize=12, fontweight='bold')\n",
    "    ax3.set_ylabel('Inference Time (ms)', fontsize=12, fontweight='bold')\n",
    "    ax3.set_title('Inference Time vs Sparsity', fontsize=13, fontweight='bold')\n",
    "    ax3.legend(fontsize=9)\n",
    "    ax3.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # ========== Plot 4: Heuristic Comparison ==========\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    methods = ['Baseline']\n",
    "    accuracies = [baseline['accuracy']]\n",
    "    colors = ['green']\n",
    "    \n",
    "    if mag_results:\n",
    "        methods.append('Magnitude\\n(70%)')\n",
    "        accuracies.append(mag_results[-1]['accuracy'])\n",
    "        colors.append('#2E86AB')\n",
    "    \n",
    "    if rand_results:\n",
    "        methods.append('Random\\n(70%)')\n",
    "        accuracies.append(rand_results[-1]['accuracy'])\n",
    "        colors.append('#A23B72')\n",
    "    \n",
    "    if layer_results:\n",
    "        methods.append('Layer-wise\\n(70%)')\n",
    "        accuracies.append(layer_results[-1]['accuracy'])\n",
    "        colors.append('#F18F01')\n",
    "    \n",
    "    bars = ax4.bar(methods, accuracies, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    ax4.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    ax4.set_title('Pruning Heuristics Comparison (70% Sparsity)', fontsize=13, fontweight='bold')\n",
    "    ax4.set_ylim([min(accuracies)-5, 100])\n",
    "    ax4.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}%',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # ========== Plot 5: Iterative vs One-shot ==========\n",
    "    ax5 = fig.add_subplot(gs[1, 2])\n",
    "    \n",
    "    comparison_methods = ['Baseline']\n",
    "    comparison_accs = [baseline['accuracy']]\n",
    "    comparison_colors = ['green']\n",
    "    \n",
    "    if iter_results:\n",
    "        comparison_methods.append('Iterative\\nPruning')\n",
    "        comparison_accs.append(iter_results[-1]['accuracy'])\n",
    "        comparison_colors.append('#C73E1D')\n",
    "    \n",
    "    if oneshot_results:\n",
    "        comparison_methods.append('One-shot\\nPruning')\n",
    "        comparison_accs.append(oneshot_results[-1]['accuracy'])\n",
    "        comparison_colors.append('#6A4C93')\n",
    "    \n",
    "    bars = ax5.bar(comparison_methods, comparison_accs, color=comparison_colors, \n",
    "                   alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    ax5.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    ax5.set_title('Iterative vs One-shot (70% Target)', fontsize=13, fontweight='bold')\n",
    "    ax5.set_ylim([min(comparison_accs)-5, 100])\n",
    "    ax5.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}%',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # ========== Plot 6: Iterative Pruning Progress ==========\n",
    "    ax6 = fig.add_subplot(gs[2, :2])\n",
    "    \n",
    "    if iter_results:\n",
    "        steps = [r['step'] for r in iter_results]\n",
    "        sparsities = [r['sparsity'] for r in iter_results]\n",
    "        accuracies = [r['accuracy'] for r in iter_results]\n",
    "        \n",
    "        ax6_twin = ax6.twinx()\n",
    "        \n",
    "        line1 = ax6.plot(steps, sparsities, 'o-', label='Sparsity', \n",
    "                        linewidth=3, markersize=10, color='#C73E1D')\n",
    "        line2 = ax6_twin.plot(steps, accuracies, 's-', label='Accuracy', \n",
    "                             linewidth=3, markersize=10, color='#2E86AB')\n",
    "        \n",
    "        ax6.set_xlabel('Pruning Step', fontsize=12, fontweight='bold')\n",
    "        ax6.set_ylabel('Sparsity (%)', fontsize=12, fontweight='bold', color='#C73E1D')\n",
    "        ax6_twin.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold', color='#2E86AB')\n",
    "        ax6.set_title('Iterative Pruning: Progressive Sparsity & Accuracy', \n",
    "                     fontsize=13, fontweight='bold')\n",
    "        \n",
    "        ax6.tick_params(axis='y', labelcolor='#C73E1D')\n",
    "        ax6_twin.tick_params(axis='y', labelcolor='#2E86AB')\n",
    "        \n",
    "        # Combine legends\n",
    "        lines = line1 + line2\n",
    "        labels = [l.get_label() for l in lines]\n",
    "        ax6.legend(lines, labels, loc='center left', fontsize=10)\n",
    "        ax6.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # ========== Plot 7: Summary Table ==========\n",
    "    ax7 = fig.add_subplot(gs[2, 2])\n",
    "    ax7.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Method', 'Sparsity\\n(%)', 'Accuracy\\n(%)', 'Size\\n(MB)', 'Time\\n(ms)', 'Params\\nRemaining']\n",
    "    ]\n",
    "    \n",
    "    total_baseline_params = baseline.get('total_params', 0)\n",
    "    \n",
    "    table_data.append([\n",
    "        'Baseline', \n",
    "        '0.0', \n",
    "        f\"{baseline['accuracy']:.2f}\", \n",
    "        f\"{baseline['size_mb']:.2f}\", \n",
    "        f\"{baseline['inf_time']:.2f}\",\n",
    "        f\"{total_baseline_params:,}\" if total_baseline_params > 0 else \"N/A\"\n",
    "    ])\n",
    "    \n",
    "    if mag_results and len(mag_results) > 0:\n",
    "        r = mag_results[-1]\n",
    "        table_data.append([\n",
    "            'Magnitude', \n",
    "            f\"{r['sparsity']:.1f}\", \n",
    "            f\"{r['accuracy']:.2f}\",\n",
    "            f\"{r['size_mb']:.2f}\", \n",
    "            f\"{r['inf_time']:.2f}\",\n",
    "            f\"{r.get('non_zero_params', 0):,}\"\n",
    "        ])\n",
    "    \n",
    "    if rand_results and len(rand_results) > 0:\n",
    "        r = rand_results[-1]\n",
    "        table_data.append([\n",
    "            'Random', \n",
    "            f\"{r['sparsity']:.1f}\", \n",
    "            f\"{r['accuracy']:.2f}\",\n",
    "            f\"{r['size_mb']:.2f}\", \n",
    "            f\"{r['inf_time']:.2f}\",\n",
    "            f\"{r.get('non_zero_params', 0):,}\"\n",
    "        ])\n",
    "    \n",
    "    if layer_results and len(layer_results) > 0:\n",
    "        r = layer_results[-1]\n",
    "        table_data.append([\n",
    "            'Layer-wise', \n",
    "            f\"{r['sparsity']:.1f}\", \n",
    "            f\"{r['accuracy']:.2f}\",\n",
    "            f\"{r['size_mb']:.2f}\", \n",
    "            f\"{r['inf_time']:.2f}\",\n",
    "            f\"{r.get('non_zero_params', 0):,}\"\n",
    "        ])\n",
    "    \n",
    "    if iter_results and len(iter_results) > 0:\n",
    "        r = iter_results[-1]\n",
    "        table_data.append([\n",
    "            'Iterative', \n",
    "            f\"{r['sparsity']:.1f}\", \n",
    "            f\"{r['accuracy']:.2f}\",\n",
    "            f\"{r['size_mb']:.2f}\", \n",
    "            f\"{r['inf_time']:.2f}\",\n",
    "            f\"{r.get('non_zero_params', 0):,}\"\n",
    "        ])\n",
    "    \n",
    "    if oneshot_results and len(oneshot_results) > 0:\n",
    "        r = oneshot_results[-1]\n",
    "        table_data.append([\n",
    "            'One-shot', \n",
    "            f\"{r['sparsity']:.1f}\", \n",
    "            f\"{r['accuracy']:.2f}\",\n",
    "            f\"{r['size_mb']:.2f}\", \n",
    "            f\"{r['inf_time']:.2f}\",\n",
    "            f\"{r.get('non_zero_params', 0):,}\"\n",
    "        ])\n",
    "    \n",
    "    table = ax7.table(cellText=table_data, cellLoc='center', loc='center',\n",
    "                     colWidths=[0.18, 0.12, 0.12, 0.12, 0.12, 0.16])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 2.5)\n",
    "    \n",
    "    # Style header row\n",
    "    for i in range(len(table_data[0])):\n",
    "        cell = table[(0, i)]\n",
    "        cell.set_facecolor('#2E86AB')\n",
    "        cell.set_text_props(weight='bold', color='white', fontsize=9)\n",
    "    \n",
    "    # Style data rows with alternating colors\n",
    "    for i in range(1, len(table_data)):\n",
    "        for j in range(len(table_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i % 2 == 0:\n",
    "                cell.set_facecolor('#F0F0F0')\n",
    "            else:\n",
    "                cell.set_facecolor('white')\n",
    "    \n",
    "    plt.suptitle('PPE Detection Model Pruning - Comprehensive Results', \n",
    "                 fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    plt.savefig('pruning_comprehensive_results.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Comprehensive results saved to 'pruning_comprehensive_results.png'\")\n",
    "    print(\"=\"*70)\n",
    "    plt.show()\n",
    "\n",
    "def print_summary(baseline, mag_results, rand_results, layer_results, \n",
    "                 iter_results, oneshot_results):\n",
    "    \"\"\"Print a text summary of all results\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PRUNING EXPERIMENTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\n{'Method':<20} {'Sparsity':<12} {'Accuracy':<12} {'Size (MB)':<12} {'Speedup':<10}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    print(f\"{'Baseline':<20} {'0.0%':<12} {baseline['accuracy']:>6.2f}% {baseline['size_mb']:>9.2f} {'1.00x':<10}\")\n",
    "    \n",
    "    if mag_results:\n",
    "        for i, r in enumerate(mag_results):\n",
    "            label = f\"Magnitude {int(r['sparsity'])}%\"\n",
    "            speedup = baseline['inf_time'] / r['inf_time']\n",
    "            print(f\"{label:<20} {r['sparsity']:>5.1f}% {r['accuracy']:>11.2f}% {r['size_mb']:>9.2f} {speedup:>9.2f}x\")\n",
    "    \n",
    "    if rand_results:\n",
    "        for i, r in enumerate(rand_results):\n",
    "            label = f\"Random {int(r['sparsity'])}%\"\n",
    "            speedup = baseline['inf_time'] / r['inf_time']\n",
    "            print(f\"{label:<20} {r['sparsity']:>5.1f}% {r['accuracy']:>11.2f}% {r['size_mb']:>9.2f} {speedup:>9.2f}x\")\n",
    "    \n",
    "    if layer_results:\n",
    "        for i, r in enumerate(layer_results):\n",
    "            label = f\"Layer-wise {int(r['sparsity'])}%\"\n",
    "            speedup = baseline['inf_time'] / r['inf_time']\n",
    "            print(f\"{label:<20} {r['sparsity']:>5.1f}% {r['accuracy']:>11.2f}% {r['size_mb']:>9.2f} {speedup:>9.2f}x\")\n",
    "    \n",
    "    if iter_results:\n",
    "        r = iter_results[-1]\n",
    "        label = \"Iterative (final)\"\n",
    "        speedup = baseline['inf_time'] / r['inf_time']\n",
    "        print(f\"{label:<20} {r['sparsity']:>5.1f}% {r['accuracy']:>11.2f}% {r['size_mb']:>9.2f} {speedup:>9.2f}x\")\n",
    "    \n",
    "    if oneshot_results:\n",
    "        r = oneshot_results[-1]\n",
    "        label = \"One-shot\"\n",
    "        speedup = baseline['inf_time'] / r['inf_time']\n",
    "        print(f\"{label:<20} {r['sparsity']:>5.1f}% {r['accuracy']:>11.2f}% {r['size_mb']:>9.2f} {speedup:>9.2f}x\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Key findings\n",
    "    print(\"\\nKEY FINDINGS:\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    if mag_results and rand_results:\n",
    "        mag_acc = mag_results[-1]['accuracy']\n",
    "        rand_acc = rand_results[-1]['accuracy']\n",
    "        print(f\"1. Magnitude pruning outperforms random pruning by {mag_acc - rand_acc:.2f}%\")\n",
    "    \n",
    "    if iter_results and oneshot_results:\n",
    "        iter_acc = iter_results[-1]['accuracy']\n",
    "        oneshot_acc = oneshot_results[-1]['accuracy']\n",
    "        diff = iter_acc - oneshot_acc\n",
    "        if diff > 0:\n",
    "            print(f\"2. Iterative pruning achieves {diff:.2f}% higher accuracy than one-shot\")\n",
    "        else:\n",
    "            print(f\"2. One-shot pruning achieves {abs(diff):.2f}% higher accuracy than iterative\")\n",
    "    \n",
    "    if mag_results:\n",
    "        final_sparsity = mag_results[-1]['sparsity']\n",
    "        size_reduction = (1 - mag_results[-1]['size_mb'] / baseline['size_mb']) * 100\n",
    "        acc_drop = baseline['accuracy'] - mag_results[-1]['accuracy']\n",
    "        print(f\"3. At {final_sparsity:.1f}% sparsity: {size_reduction:.1f}% size reduction with {acc_drop:.2f}% accuracy drop\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"PPE DETECTION MODEL PRUNING EXPERIMENTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "    print(f\"Number of Classes: {NUM_CLASSES}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Setup data transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load datasets - UPDATE THESE PATHS TO YOUR DATA\n",
    "    train_images = 'train/images'\n",
    "    train_labels = 'train/labels'\n",
    "    val_images = 'valid/images'\n",
    "    val_labels = 'valid/labels'\n",
    "    \n",
    "    # Dataset mode\n",
    "    DATASET_MODE = 'crop_objects'  # Recommended for object detection\n",
    "    MULTI_LABEL = (DATASET_MODE == 'multi_label')\n",
    "    \n",
    "    print(f\"\\nDataset Configuration:\")\n",
    "    print(f\"  Mode: {DATASET_MODE}\")\n",
    "    print(f\"  Multi-label: {MULTI_LABEL}\")\n",
    "    \n",
    "    print(\"\\nLoading datasets...\")\n",
    "    train_dataset = PPEDataset(train_images, train_labels, transform=transform, mode=DATASET_MODE)\n",
    "    val_dataset = PPEDataset(val_images, val_labels, transform=transform, mode=DATASET_MODE)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    print(f\"  Train samples: {len(train_dataset)}\")\n",
    "    print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # BASELINE MODEL TRAINING\n",
    "    # ==============================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 1: TRAINING BASELINE MODEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model = create_model(multi_label=MULTI_LABEL)\n",
    "    \n",
    "    if MULTI_LABEL:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    print(\"\\nTraining baseline model...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, MULTI_LABEL)\n",
    "        val_acc, val_time = evaluate(model, val_loader, MULTI_LABEL)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Baseline metrics\n",
    "    baseline_acc, baseline_time = evaluate(model, val_loader, MULTI_LABEL)\n",
    "    baseline_size = get_model_size(model)\n",
    "    baseline_sparsity = get_sparsity(model)\n",
    "    total_params, non_zero_params = count_parameters(model)\n",
    "    \n",
    "    baseline = {\n",
    "        'accuracy': baseline_acc,\n",
    "        'size_mb': baseline_size,\n",
    "        'inf_time': baseline_time,\n",
    "        'sparsity': baseline_sparsity,\n",
    "        'total_params': total_params,\n",
    "        'non_zero_params': non_zero_params\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"BASELINE MODEL METRICS:\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"Accuracy: {baseline_acc:.2f}%\")\n",
    "    print(f\"Model Size: {baseline_size:.2f} MB\")\n",
    "    print(f\"Inference Time: {baseline_time:.2f} ms\")\n",
    "    print(f\"Parameters: {total_params:,}\")\n",
    "    print(f\"Initial Sparsity: {baseline_sparsity:.2f}%\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Save baseline model\n",
    "    torch.save(model.state_dict(), 'baseline_model.pth')\n",
    "    print(\"Baseline model saved to 'baseline_model.pth'\")\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # EXPERIMENT 1: MAGNITUDE PRUNING (Different Levels)\n",
    "    # ==============================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 2: MAGNITUDE-BASED PRUNING EXPERIMENTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    mag_results = []\n",
    "    for prune_amount in [0.3, 0.5, 0.7]:\n",
    "        print(f\"\\n{'*'*70}\")\n",
    "        print(f\"Magnitude Pruning: {prune_amount*100:.0f}% Target Sparsity\")\n",
    "        print(f\"{'*'*70}\")\n",
    "        \n",
    "        model_mag = copy.deepcopy(model)\n",
    "        model_mag = magnitude_pruning(model_mag, prune_amount)\n",
    "        model_mag = fine_tune(model_mag, train_loader, val_loader, epochs=5, multi_label=MULTI_LABEL)\n",
    "        model_mag = make_pruning_permanent(model_mag)\n",
    "        \n",
    "        sparsity = get_sparsity(model_mag)\n",
    "        accuracy, inf_time = evaluate(model_mag, val_loader, MULTI_LABEL)\n",
    "        size_mb = get_model_size(model_mag)\n",
    "        total_params, non_zero_params = count_parameters(model_mag)\n",
    "        \n",
    "        mag_results.append({\n",
    "            'sparsity': sparsity,\n",
    "            'accuracy': accuracy,\n",
    "            'size_mb': size_mb,\n",
    "            'inf_time': inf_time,\n",
    "            'total_params': total_params,\n",
    "            'non_zero_params': non_zero_params\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Achieved Sparsity: {sparsity:.2f}%\")\n",
    "        print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"  Model Size: {size_mb:.2f} MB\")\n",
    "        print(f\"  Inference Time: {inf_time:.2f} ms\")\n",
    "        print(f\"  Parameters: {non_zero_params:,} / {total_params:,}\")\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # EXPERIMENT 2: RANDOM PRUNING\n",
    "    # ==============================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 3: RANDOM PRUNING EXPERIMENTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    rand_results = []\n",
    "    for prune_amount in [0.3, 0.5, 0.7]:\n",
    "        print(f\"\\n{'*'*70}\")\n",
    "        print(f\"Random Pruning: {prune_amount*100:.0f}% Target Sparsity\")\n",
    "        print(f\"{'*'*70}\")\n",
    "        \n",
    "        model_rand = copy.deepcopy(model)\n",
    "        model_rand = random_pruning(model_rand, prune_amount)\n",
    "        model_rand = fine_tune(model_rand, train_loader, val_loader, epochs=5, multi_label=MULTI_LABEL)\n",
    "        model_rand = make_pruning_permanent(model_rand)\n",
    "        \n",
    "        sparsity = get_sparsity(model_rand)\n",
    "        accuracy, inf_time = evaluate(model_rand, val_loader, MULTI_LABEL)\n",
    "        size_mb = get_model_size(model_rand)\n",
    "        total_params, non_zero_params = count_parameters(model_rand)\n",
    "        \n",
    "        rand_results.append({\n",
    "            'sparsity': sparsity,\n",
    "            'accuracy': accuracy,\n",
    "            'size_mb': size_mb,\n",
    "            'inf_time': inf_time,\n",
    "            'total_params': total_params,\n",
    "            'non_zero_params': non_zero_params\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Achieved Sparsity: {sparsity:.2f}%\")\n",
    "        print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"  Model Size: {size_mb:.2f} MB\")\n",
    "        print(f\"  Inference Time: {inf_time:.2f} ms\")\n",
    "        print(f\"  Parameters: {non_zero_params:,} / {total_params:,}\")\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # EXPERIMENT 3: LAYER-WISE PRUNING\n",
    "    # ==============================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 4: LAYER-WISE PRUNING EXPERIMENTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    layer_results = []\n",
    "    for prune_amount in [0.3, 0.5, 0.7]:\n",
    "        print(f\"\\n{'*'*70}\")\n",
    "        print(f\"Layer-wise Pruning: {prune_amount*100:.0f}% Per Layer\")\n",
    "        print(f\"{'*'*70}\")\n",
    "        \n",
    "        model_layer = copy.deepcopy(model)\n",
    "        model_layer = layerwise_pruning(model_layer, prune_amount)\n",
    "        model_layer = fine_tune(model_layer, train_loader, val_loader, epochs=5, multi_label=MULTI_LABEL)\n",
    "        model_layer = make_pruning_permanent(model_layer)\n",
    "        \n",
    "        sparsity = get_sparsity(model_layer)\n",
    "        accuracy, inf_time = evaluate(model_layer, val_loader, MULTI_LABEL)\n",
    "        size_mb = get_model_size(model_layer)\n",
    "        total_params, non_zero_params = count_parameters(model_layer)\n",
    "        \n",
    "        layer_results.append({\n",
    "            'sparsity': sparsity,\n",
    "            'accuracy': accuracy,\n",
    "            'size_mb': size_mb,\n",
    "            'inf_time': inf_time,\n",
    "            'total_params': total_params,\n",
    "            'non_zero_params': non_zero_params\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Achieved Sparsity: {sparsity:.2f}%\")\n",
    "        print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"  Model Size: {size_mb:.2f} MB\")\n",
    "        print(f\"  Inference Time: {inf_time:.2f} ms\")\n",
    "        print(f\"  Parameters: {non_zero_params:,} / {total_params:,}\")\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # EXPERIMENT 4: ITERATIVE VS ONE-SHOT PRUNING\n",
    "    # ==============================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 5: ITERATIVE VS ONE-SHOT PRUNING COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Iterative Pruning\n",
    "    print(f\"\\n{'*'*70}\")\n",
    "    print(\"Iterative Pruning (5 steps to 70% sparsity)\")\n",
    "    print(f\"{'*'*70}\")\n",
    "    model_iter = copy.deepcopy(model)\n",
    "    model_iter, iter_results = iterative_pruning(\n",
    "        model_iter, train_loader, val_loader, \n",
    "        target_sparsity=0.7, steps=5, multi_label=MULTI_LABEL\n",
    "    )\n",
    "    \n",
    "    # One-shot Pruning\n",
    "    print(f\"\\n{'*'*70}\")\n",
    "    print(\"One-shot Pruning (Direct to 70% sparsity)\")\n",
    "    print(f\"{'*'*70}\")\n",
    "    model_oneshot = copy.deepcopy(model)\n",
    "    model_oneshot, oneshot_results = oneshot_pruning(\n",
    "        model_oneshot, train_loader, val_loader, \n",
    "        target_sparsity=0.7, multi_label=MULTI_LABEL\n",
    "    )\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # SAVE BEST MODELS\n",
    "    # ==============================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SAVING PRUNED MODELS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    torch.save(model_iter.state_dict(), 'model_iterative_pruned.pth')\n",
    "    print(\"Iterative pruned model saved to 'model_iterative_pruned.pth'\")\n",
    "    \n",
    "    torch.save(model_oneshot.state_dict(), 'model_oneshot_pruned.pth')\n",
    "    print(\"One-shot pruned model saved to 'model_oneshot_pruned.pth'\")\n",
    "    \n",
    "    if mag_results:\n",
    "        model_mag_best = copy.deepcopy(model)\n",
    "        model_mag_best = magnitude_pruning(model_mag_best, 0.7)\n",
    "        model_mag_best = fine_tune(model_mag_best, train_loader, val_loader, epochs=5, multi_label=MULTI_LABEL)\n",
    "        model_mag_best = make_pruning_permanent(model_mag_best)\n",
    "        torch.save(model_mag_best.state_dict(), 'model_magnitude_pruned.pth')\n",
    "        print(\"Magnitude pruned model saved to 'model_magnitude_pruned.pth'\")\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # VISUALIZATION AND SUMMARY\n",
    "    # ==============================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERATING COMPREHENSIVE VISUALIZATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    plot_comprehensive_results(baseline, mag_results, rand_results, layer_results, \n",
    "                               iter_results, oneshot_results)\n",
    "    \n",
    "    print_summary(baseline, mag_results, rand_results, layer_results, \n",
    "                 iter_results, oneshot_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXPERIMENTS COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nGenerated Files:\")\n",
    "    print(\"  1. baseline_model.pth - Original trained model\")\n",
    "    print(\"  2. model_iterative_pruned.pth - Best iterative pruned model\")\n",
    "    print(\"  3. model_oneshot_pruned.pth - One-shot pruned model\")\n",
    "    print(\"  4. model_magnitude_pruned.pth - Magnitude pruned model\")\n",
    "    print(\"  5. pruning_comprehensive_results.png - Visualization of all results\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
